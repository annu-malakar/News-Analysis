{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30c1b2cb-69c8-407c-8e43-27372cb06faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your text:  I kill a girl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarized Text:\n",
      "- I kill a girl\n",
      "\n",
      "Sentiment: Negative\n",
      "Predicted Category: Politics\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from heapq import nlargest\n",
    "\n",
    "# Initialize Sentiment Analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define stopwords for text preprocessing\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def tfidf_summarize(article_text, num_sentences=3):\n",
    "    # Tokenize the article into sentences\n",
    "    sentences = sent_tokenize(article_text)\n",
    "    \n",
    "    # Initialize TF-IDF vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    # Fit and transform the article text\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
    "    \n",
    "    # Calculate sentence scores based on TF-IDF\n",
    "    sentence_scores = {}\n",
    "    for i in range(len(sentences)):\n",
    "        score = sum(tfidf_matrix[i].toarray()[0])\n",
    "        sentence_scores[sentences[i]] = score\n",
    "    \n",
    "    # Select top N sentences with highest scores\n",
    "    summarized_sentences = nlargest(num_sentences, sentence_scores, key=sentence_scores.get)\n",
    "    \n",
    "    return summarized_sentences\n",
    "\n",
    "def predict_category(article_text):\n",
    "    # Convert article text to lowercase for case-insensitive matching\n",
    "    article_text_lower = article_text.lower()\n",
    "\n",
    "    # Define keywords or phrases indicative of different categories\n",
    "    categories = {\n",
    "        'Politics': ['election', 'government', 'parliament', 'minister', 'president','MLA'],\n",
    "        'Sports': ['football', 'soccer', 'basketball', 'tennis', 'olympics', 'cricket','players','game'],\n",
    "        'Technology': ['tech', 'innovation', 'digital', 'internet', 'software','smartphone'],\n",
    "        'Entertainment': ['movie', 'music', 'celebrity', 'entertainment', 'film'],\n",
    "        'Education': ['books','exams','students','teacher','school','college','university'],\n",
    "        'Business': ['economy', 'finance', 'stock', 'market', 'business','money'],\n",
    "        'Weather' : ['climate'],\n",
    "        'Health'  : ['hospitals', 'medication', 'cholestrol','drug','disease']\n",
    "    }\n",
    "\n",
    "    # Count occurrences of keywords or phrases from each category\n",
    "    category_counts = {category: sum(keyword in article_text_lower for keyword in keywords) \n",
    "                       for category, keywords in categories.items()}\n",
    "\n",
    "    # Predict the category with the highest count\n",
    "    predicted_category = max(category_counts, key=category_counts.get)\n",
    "\n",
    "    return predicted_category\n",
    "\n",
    "def process_input(user_input):\n",
    "    # Sentiment analysis\n",
    "    preprocessed_input = preprocess_text(user_input)\n",
    "    sentiment_scores = analyzer.polarity_scores(preprocessed_input)\n",
    "    if sentiment_scores['compound'] >= 0.05:\n",
    "        overall_sentiment = \"Positive\"\n",
    "    elif sentiment_scores['compound'] <= -0.05:\n",
    "        overall_sentiment = \"Negative\"\n",
    "    else:\n",
    "        overall_sentiment = \"Neutral\"\n",
    "    \n",
    "    summarized_text = tfidf_summarize(user_input)\n",
    "    predicted_category = predict_category(user_input)\n",
    "    \n",
    "    return summarized_text, overall_sentiment, predicted_category\n",
    "\n",
    "# Take input from the user\n",
    "user_input = input(\"Enter your text: \")\n",
    "\n",
    "# Process the input\n",
    "summarized_text, sentiment, category = process_input(user_input)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nSummarized Text:\")\n",
    "for sentence in summarized_text:\n",
    "    print(\"-\", sentence)\n",
    "print(\"\\nSentiment:\", sentiment)\n",
    "print(\"Predicted Category:\", category)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
